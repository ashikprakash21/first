import numpy as np 
import matplotlib.pyplot as plt 
import matplotlib.colors as mcolors
import pandas as pd 
import random
import math
import time
from sklearn.linear_model import LinearRegression, BayesianRidge
from sklearn.model_selection import RandomizedSearchCV, train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, mean_absolute_error
import datetime
import operator 
plt.style.use('fivethirtyeight')
%matplotlib inline
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('retina')
import warnings
warnings.filterwarnings("ignore")

### The code below builds a plot with 'fivethirtyeight' style, a style similar to the plots on fivethirtyeight.com.
### Its's just that the definition of the displayed plot is a bit better: retina quality. Any display with retina 
    resolution will make the figures look better 

confirmed_df = pd.read_csv('/home/user/Desktop/csv files/confirmed_cases.csv')
deaths_df = pd.read_csv('/home/user/Desktop/csv files/deaths.csv')
latest_data = pd.read_csv('/home/user/Desktop/csv files/latest.csv')

## these are the three datasets we used confirmed corona cases,death cases reported and information about latest covid datas.
## these are downloaded from kaggle.

latest_data.head(20)  #to show top 20 rows data.

##in that dataframe we can identify the presence of null values.so we have to remove it or handle effectively.

latest_data = latest_data.drop(['FIPS','Admin2'],axis =1)
latest_data['Province_State'].fillna(latest_data['Country_Region'],inplace=True)  #the state names are missing in the column so we just copied the country name as state name .

confirmed_df.dtypes  #checking the datatypes of columns in confirmed dataframe.

confirmed_df.isna().sum()  #display the total null values present.


#checking the number of duplicate values
confirmed_df.duplicated().sum()

confirmed_df['Province/State'].fillna(confirmed_df['Country/Region'], inplace=True)

#correlation checking is not needed here
corri = confirmed_df.corr()
corri

#here correlation low columns are more , so if avoided it will totally destroy data value.
corri[abs(corri)<.10].index.shape[0] 

# import seaborn as sns
# sns.pairplot(confirmed_df,hue = 'TARGET CLASS')


#packages needed for visualization are imported
import seaborn as sns              
import matplotlib.pyplot as plt
%matplotlib inline


##plotting the correlation map
 plt.figure(figsize=(14,12))
 sns.heatmap(confirmed_df.corr(), annot =True)
 plt.title("Correlation Map", fontweight = "bold", fontsize=10)


numcols = confirmed_df.dtypes[(confirmed_df.dtypes=='int64') | (confirmed_df.dtypes=='float64')].index

#displaying the latitude and longitude columns.
numcols1 = confirmed_df[(['Lat','Long'])]
numcols1

#verifying whether there's a 0.0 value present.
confirmed_df[(confirmed_df['Lat']==0.0)| (confirmed_df['Long']==0.0)].shape[0]

#outliers checking using boxplot. 
for x in numcols1:
    sns.boxplot(confirmed_df[x],orient='h')
    plt.title(x)
    plt.show()

confirmed_df

cols = confirmed_df.keys()

#Get all the dates for the ongoing coronavirus pandemic


cols #viewing the names of columns

#taking all columns except first four categorical columns.because we can train data using contonous variables.
confirmed = confirmed_df.loc[:, cols[4]:cols[-1]]
deaths = deaths_df.loc[:, cols[4]:cols[-1]]


dates = confirmed.keys()
world_cases = []
total_deaths = [] 
mortality_rate = []
for i in dates:
    confirmed_sum = confirmed[i].sum()
    death_sum = deaths[i].sum()
   # confirmed, deaths, recovered, and active
    world_cases.append(confirmed_sum)
    total_deaths.append(death_sum)
   # calculate rates
    mortality_rate.append(death_sum/confirmed_sum)


confirmed.keys()


#Getting daily increases and moving averages
def daily_increase(data):
    d = [] 
    for i in range(len(data)):
        if i == 0:
            d.append(data[0])
        else:
            d.append(data[i]-data[i-1])
    return d 
def moving_average(data, window_size):
    moving_average = []
    for i in range(len(data)):
        if i + window_size < len(data):
            moving_average.append(np.mean(data[i:i+window_size]))
        else:
            moving_average.append(np.mean(data[i:len(data)]))
    return moving_average
#window size
window = 7
# confirmed cases
world_daily_increase = daily_increase(world_cases)
world_confirmed_avg= moving_average(world_cases, window)
world_daily_increase_avg = moving_average(world_daily_increase, window)
# deaths
world_daily_death = daily_increase(total_deaths)
world_death_avg = moving_average(total_deaths, window)
world_daily_death_avg = moving_average(world_daily_death, window)

#found daily increase rates and moving average in a period of 7 days.

#just showing the world cases for confirmed cases.
world_cases


#reshaping the list.
#reshaped the list into an array 
days_since_1_22 = np.array([i for i in range(len(dates))]).reshape(-1, 1)
world_cases = np.array(world_cases).reshape(-1, 1)
total_deaths = np.array(total_deaths).reshape(-1, 1)

#now we can see the diff.
world_cases
